{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Tumor Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the necessary libraries. We'll use Keras with TensorFlow Backend for our CNN and VGG16 as the pre trained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications import VGG16\n",
    "import matplotlib.pyplot as plt ## to plot accuracy and loss graphs \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "\n",
    "As we have very less training data there is a high chance of overfitting. To overcome this, we use data augmentation which is done by the ImageDataGenerator present in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, fill_mode='nearest')\n",
    "## vertical_flip is not needed as Brain MRI's have the same vertical orientation.\n",
    "valid_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the flow_from_directory method to load the images from their respective paths. We also specify our target_size and the batch_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_gen.flow_from_directory('/path/to/training/images', target_size = (160,160), batch_size=10, \n",
    "                                      class_mode='binary')\n",
    "valid = valid_gen.flow_from_directory('/path/to/validation/images', target_size = (160,160), batch_size=10, \n",
    "                                      class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model\n",
    "\n",
    "We create our Sequential Model. The model consists of 2 convolutional blocks followed by Flatten and a fully-connected layer with Dropout to reduce overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 158, 158, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 79, 79, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 77, 77, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 38, 38, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 23104)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               5914880   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 5,916,529\n",
      "Trainable params: 5,916,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(8, 3, activation='relu', input_shape=(160,160,3)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Conv2D(16, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid')) ## Output layer\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compile the model. I use SGD with momentum as optimizer and the learning rate is kept very small. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd1 = SGD(lr=9e-5, decay=1e-6, momentum=0.99)\n",
    "model.compile(optimizer=sgd1, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit_generator(train, steps_per_epoch=22, epochs=50, validation_data=valid, validation_steps=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting accuracy graph\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting loss graph\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Trained Model\n",
    "\n",
    "I use VGG16 as the base model. Setting include_top=False ensures that the fully-connected layers of the base model are not used for training. \n",
    "Then we freeze all the weights of the layers in the base model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(160,160,3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "        layer.trainable = False ##freezing the layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we add our custom fully-connected layers on top of the base model. In step 1 the weights of these layers will be updated. 2 fully-connected layers are used with Dropout between them to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 5, 5, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              13108224  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 28,085,569\n",
      "Trainable params: 13,370,881\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_final = Sequential()\n",
    "model_final.add(base_model)\n",
    "\n",
    "model_final.add(Flatten())\n",
    "\n",
    "model_final.add(Dense(1024, activation='relu'))\n",
    "model_final.add(Dropout(0.4))\n",
    "model_final.add(Dense(256, activation='relu'))\n",
    "model_final.add(Dense(1, activation='sigmoid'))\n",
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compile our pre trained model. Again we use SGD with momentum as optimizer with a small learning rate. This time we train only for 25 epochs. Only the fully-connected layers will be trained in this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1\n",
    "sgd2 = SGD(lr=1e-4, decay=1e-6, momentum=0.9)\n",
    "model_final.compile(optimizer=sgd2, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_final.fit_generator(train, steps_per_epoch=22, epochs=25, validation_data=valid, validation_steps=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now step 2 begins. We first reset our ImageDataGenerators and the unfreeze the final convolutional block of the base model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset()\n",
    "valid.reset()\n",
    " \n",
    "for layer in base_model.layers[15:]:\n",
    "    layer.trainable = True ## unfreezing the last convolutional block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we compile the model using the same optimizer in step 1. This time the layers present in the last convolutional block of VGG16 will also be trained along with the fully-connected layers. We train the model for 25 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2\n",
    "model_final.compile(optimizer=sgd2, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "hist = model_final.fit_generator(train, steps_per_epoch=22, epochs=25, validation_data=valid, validation_steps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting accuracy graph\n",
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting loss graph\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
